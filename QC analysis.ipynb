{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import statistics as stat\n",
    "from datetime import datetime\n",
    "import operator\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Data Test Cases:\n",
    "1. All messages that have images in Telegram, should have the correct number of images downloaded and recorded in json file\n",
    "2. All downloaded images should have the correct corresponding ID of the post that stores text, emoji, other metadata in Telegram. [for each dowloaded file the file ID matches the Post ID. For each Post ID there is dowloaded file with corresponding ID]\n",
    "3. All images recorded in files should have downloaded images in folders\n",
    "4. All messages that have emojis on Telegram should have emojis in files\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA/QC \n",
    "The script to get the numeric stats for the data collection\n",
    "TODO: make this a table instead of the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_metrics(data):\n",
    "    counts = {\"none_views_post\": 0, \"none_fwd_post\": 0, \"url_new\": 0, \"url_old\": 0, \"url\": 0, \"total_url_from_text\": 0,\n",
    "              \"post_with_url\": 0, \"total_fwd_posts\": 0, \"total_views\": 0, \"total_fwds\": 0,\n",
    "             \"lowest_views\": float('inf'), \"highest_views\": float('-inf'), \n",
    "              \"lowest_fwds\": float('inf'), \"highest_fwds\": float('-inf'),\n",
    "             \"post_with_views\": 0, \"average_views\": 0.0, \n",
    "             \"lowest_text_length\": float('inf'), \"highest_text_length\": float('-inf')}\n",
    "\n",
    "    url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "    for i in data.keys():\n",
    "        post = data[i]\n",
    "            \n",
    "        if post.get('total_views') == None:\n",
    "            print(f\"message ID {post['id']} has no view count.\")\n",
    "            counts[\"none_views_post\"] += 1\n",
    "        else:\n",
    "            views = post.get('total_views')\n",
    "            counts[\"total_views\"] += views\n",
    "            counts[\"post_with_views\"] += 1\n",
    "            \n",
    "            if views < counts[\"lowest_views\"]:\n",
    "                counts[\"lowest_views\"] = views\n",
    "            if views > counts[\"highest_views\"]:\n",
    "                counts[\"highest_views\"] = views\n",
    "\n",
    "        if post.get('total_fwds') == None:\n",
    "            counts[\"none_fwd_post\"] += 1\n",
    "        else:\n",
    "            fwds = post.get('total_fwds')\n",
    "            counts[\"total_fwds\"] += fwds\n",
    "            if fwds < counts[\"lowest_fwds\"]:\n",
    "                counts[\"lowest_fwds\"] = fwds\n",
    "            if fwds > counts[\"highest_fwds\"]:\n",
    "                counts[\"highest_fwds\"] = fwds\n",
    "                \n",
    "        if any('url' in item for item in post.get('media', [])):\n",
    "            counts[\"url_new\"] += 1\n",
    "            counts[\"url\"] += 1\n",
    "\n",
    "        if 'url' in post:\n",
    "            counts[\"url_old\"] += 1\n",
    "            counts[\"url\"] += 1\n",
    "\n",
    "        if 'text' in post and isinstance(post['text'], str):\n",
    "            urls_in_text = url_pattern.findall(post['text'])\n",
    "            if urls_in_text:\n",
    "#                 print(post['id'], post['text'])\n",
    "                counts[\"total_url_from_text\"] += len(urls_in_text)\n",
    "                counts[\"post_with_url\"] += 1\n",
    "        if 'fwd' in post:\n",
    "            counts[\"total_fwd_posts\"] += 1\n",
    "        \n",
    "        if 'text' in post and isinstance(post['text'], str):\n",
    "            text_length = len(post['text'])\n",
    "            if text_length < counts[\"lowest_text_length\"]:\n",
    "                counts[\"lowest_text_length\"] = text_length\n",
    "            if text_length > counts[\"highest_text_length\"]:\n",
    "                counts[\"highest_text_length\"] = text_length\n",
    "    \n",
    "    # average views\n",
    "    if counts[\"post_with_views\"] > 0:\n",
    "        counts[\"average_views\"] = counts[\"total_views\"] / counts[\"post_with_views\"]\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sys.stdout = open('QC.txt', 'w')\n",
    "\n",
    "main_folder = \"/Users/dalyapraz/Library/CloudStorage/OneDrive-SharedLibraries-IndianaUniversity/Kouper, Inna - 2023 Summer work/Quantitative data collection\"\n",
    "\n",
    "period_totals = {}\n",
    "\n",
    "\n",
    "# specify the order for the graph\n",
    "period_order = [\"011522-030122\", \"040122-050122\", \"060122-070122\", \"090122-101622\", \n",
    "                \"110122-120122\", \"020123-030123\", \"060123-070723\"]\n",
    "\n",
    "for folder_name in os.listdir(main_folder):\n",
    "#     if folder_name == \"eshkinkrot\":\n",
    "        folder_path = os.path.join(main_folder, folder_name)\n",
    "\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                if file_name.endswith(\".json\") and file_name != 'channel_info.json':\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                    num_posts = len(data)\n",
    "                    period = str(file_name.rsplit('_', 1)[-1].rsplit('.', 1)[0])\n",
    "                    print(f\"Folder: {folder_name}, Period: {period}, Num Posts: {num_posts}\")\n",
    "\n",
    "                    metrics = count_metrics(data)\n",
    "                    print(\"QA/QC metrics: \")\n",
    "                    for key, value in metrics.items():\n",
    "                        if key not in [\"url_new\", \"url_old\"]:\n",
    "                            print(f\"  {key}: {value}\")\n",
    "                    print()\n",
    "sys.stdout.close()\n",
    "sys.stdout = sys.__stdout__  # reset output to console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rusich_army\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a313d251760d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mid_exists_in_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a313d251760d>\u001b[0m in \u001b[0;36mid_exists_in_data\u001b[0;34m(id, data)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# sys.stdout = open('QC.txt', 'w')\n",
    "\n",
    "main_folder = \"/Users/dalyapraz/Library/CloudStorage/OneDrive-SharedLibraries-IndianaUniversity/Kouper, Inna - 2023 Summer work/Quantitative data collection October 2023\"\n",
    "\n",
    "period_totals = {}\n",
    "\n",
    "\n",
    "# specify the order for the graph\n",
    "period_order = [\"011522-030122\", \"040122-050122\", \"060122-070122\", \"090122-101622\", \n",
    "                \"110122-120122\", \"020123-030123\", \"060123-070723\"]\n",
    "\n",
    "# Function to check if a given ID exists in the provided JSON data\n",
    "def id_exists_in_data(id, data):\n",
    "    for i in data.keys():\n",
    "        post = data[i]\n",
    "        if post.get('id') == id:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for folder_name in os.listdir(main_folder):\n",
    "        print(folder_name)\n",
    "        folder_path = os.path.join(main_folder, folder_name)\n",
    "        image_folder_path = os.path.join(folder_path, \"images\")\n",
    "        doc_folder_path = os.path.join(folder_path, \"documents\")\n",
    "        extracted_file_ids = []\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Images and Docs \n",
    "            if os.path.isdir(image_folder_path) and os.path.isdir(doc_folder_path) :\n",
    "                for file_name in os.listdir(image_folder_path)+os.listdir(doc_folder_path):\n",
    "                    if \"photo\" in file_name or \"doc\" in file_name:\n",
    "                        # Extract the number that goes after \"photo\" or \"doc\" from each filename\n",
    "                        try:\n",
    "                            id_str = file_name.split(\"photo\")[1].split(\".\")[0] if \"photo\" in file_name else file_name.split(\"doc\")[1].split(\".\")[0]\n",
    "                            extracted_file_ids.append(int(id_str))\n",
    "                        except (IndexError, ValueError):\n",
    "                            print(f\"Failed to extract ID from {file_name}\")\n",
    "            # Go over the messages json files\n",
    "            json_files = [file for file in os.listdir(folder_path) if file.endswith(\".json\") and file_name != 'channel_info.json']\n",
    "            missing_associations = []\n",
    "            for extracted_id in extracted_file_ids:\n",
    "                found = False\n",
    "                for file_name in json_files:\n",
    "                    with open(os.path.join(folder_path, file_name), 'r') as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                    if id_exists_in_data(extracted_id, data):\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    missing_associations.append(extracted_id)\n",
    "        # Print or process the missing associations\n",
    "        print(f\"Folder: {folder_name}, Missing: {missing_associations}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'anti_war/no_chat' created successfully in '/Users/dalyapraz/Library/CloudStorage/OneDrive-SharedLibraries-IndianaUniversity/Kouper, Inna - 2023 Summer work/Quantitative data collection'!\n",
      "Moved nowarmetro to anti_war/no_chat\n",
      "Moved garry_kasparov_rus to anti_war/no_chat\n",
      "Moved vesna_democrat to anti_war/no_chat\n",
      "Moved eshkinkrot to anti_war/no_chat\n",
      "Moved mozhemobyasnit to anti_war/no_chat\n",
      "Moved pezduzalive to anti_war/no_chat\n",
      "Moved femagainstwar to anti_war/no_chat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "# quick script to move around the files\n",
    "main_folder = \"/Users/dalyapraz/Library/CloudStorage/OneDrive-SharedLibraries-IndianaUniversity/Kouper, Inna - 2023 Summer work/Quantitative data collection\"\n",
    "new_folder_name = \"anti_war/no_chat\"     #<----------change here\n",
    "\n",
    "# Combine the main folder path with the new folder name\n",
    "new_folder_path = os.path.join(main_folder, new_folder_name)\n",
    "\n",
    "# Create the new folder\n",
    "if not os.path.exists(new_folder_path):\n",
    "    os.makedirs(new_folder_path)\n",
    "    print(f\"Folder '{new_folder_name}' created successfully in '{main_folder}'!\")\n",
    "else:\n",
    "    print(f\"Folder '{new_folder_name}' already exists in '{main_folder}'!\")\n",
    "\n",
    "# List folder names you want to move and move them\n",
    "# no chat & anti_war \n",
    "folder_list = [\"nowarmetro\", \"garry_kasparov_rus\", \"vesna_democrat\", \"eshkinkrot\", \n",
    "               \"mozhemobyasnit\", \"pezduzalive\", \"femagainstwar\"]\n",
    "\n",
    "# # has chat & anti_war \n",
    "# folder_list = [\"zelenayalenta\", \"activatica\", \"Ateobreaking\", \"white_powder2020\", \n",
    "#                \"ArkHelps\", \"mpartisans\", \"nevzorovtv\", \"pr_russia\"]\n",
    "\n",
    "# # no chat & pro_war \n",
    "# folder_list = [\"sashakots\", \"wargonzo\", \"milinfolive\", \"Cbpub\", \"cyber_frontZ\", \"margaritasimonyan\", \n",
    "#                \"epoddubny\", \"dimsmirnov175\", \"rybar\", \"rustroyka1945\", \"vorposte\"]\n",
    "\n",
    "# has chat & pro_war \n",
    "# folder_list = [\"boris_rozhin\", \"akashevarova\", \"rusich_army\", \"warfakes\", \"dva_majors\", \"krispotupchik\", \n",
    "#                \"MariaVladimirovnaZakharova\", \"imnotbozhena\", \"RVvoenkor\", \"voenacher\", \"obshina_ru\", \"strelkovii\"]\n",
    "for folder_to_move in folder_list:\n",
    "    source_path = os.path.join(main_folder, folder_to_move)\n",
    "    destination_path = os.path.join(new_folder_path, folder_to_move)\n",
    "\n",
    "    if os.path.exists(source_path) and os.path.isdir(source_path):\n",
    "        shutil.move(source_path, destination_path)\n",
    "        print(f\"Moved {folder_to_move} to {new_folder_name}\")\n",
    "    else:\n",
    "        print(f\"Folder {folder_to_move} does not exist in {main_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
