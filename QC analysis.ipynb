{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import statistics as stat\n",
    "from datetime import datetime\n",
    "import operator\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Data Test Cases:\n",
    "1. All messages that have images in Telegram, should have the correct number of images downloaded and recorded in json file\n",
    "2. All downloaded images should have the correct corresponding ID of the post that stores text, emoji, other metadata in Telegram. [for each dowloaded file the file ID matches the Post ID. For each Post ID there is dowloaded file with corresponding ID]\n",
    "3. All images recorded in files should have downloaded images in folders\n",
    "4. All messages that have emojis on Telegram should have emojis in files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA/QC \n",
    "The script to get the numeric stats for the data collection\n",
    "TODO: make this a table instead of the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_metrics(data):\n",
    "    counts = {\"none_views_post\": 0, \"none_fwd_post\": 0, \"url_new\": 0, \"url_old\": 0, \"url\": 0, \"total_url_from_text\": 0,\n",
    "              \"post_with_url\": 0, \"total_fwd_posts\": 0, \"total_views\": 0, \"total_fwds\": 0,\n",
    "             \"lowest_views\": float('inf'), \"highest_views\": float('-inf'), \n",
    "              \"lowest_fwds\": float('inf'), \"highest_fwds\": float('-inf'),\n",
    "             \"post_with_views\": 0, \"average_views\": 0.0, \n",
    "             \"lowest_text_length\": float('inf'), \"highest_text_length\": float('-inf')}\n",
    "\n",
    "    url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "    for i in data.keys():\n",
    "        post = data[i]\n",
    "            \n",
    "        if post.get('total_views') == None:\n",
    "            print(f\"message ID {post['id']} has no view count.\")\n",
    "            counts[\"none_views_post\"] += 1\n",
    "        else:\n",
    "            views = post.get('total_views')\n",
    "            counts[\"total_views\"] += views\n",
    "            counts[\"post_with_views\"] += 1\n",
    "            \n",
    "            if views < counts[\"lowest_views\"]:\n",
    "                counts[\"lowest_views\"] = views\n",
    "            if views > counts[\"highest_views\"]:\n",
    "                counts[\"highest_views\"] = views\n",
    "\n",
    "        if post.get('total_fwds') == None:\n",
    "            counts[\"none_fwd_post\"] += 1\n",
    "        else:\n",
    "            fwds = post.get('total_fwds')\n",
    "            counts[\"total_fwds\"] += fwds\n",
    "            if fwds < counts[\"lowest_fwds\"]:\n",
    "                counts[\"lowest_fwds\"] = fwds\n",
    "            if fwds > counts[\"highest_fwds\"]:\n",
    "                counts[\"highest_fwds\"] = fwds\n",
    "                \n",
    "        if any('url' in item for item in post.get('media', [])):\n",
    "            counts[\"url_new\"] += 1\n",
    "            counts[\"url\"] += 1\n",
    "\n",
    "        if 'url' in post:\n",
    "            counts[\"url_old\"] += 1\n",
    "            counts[\"url\"] += 1\n",
    "\n",
    "        if 'text' in post and isinstance(post['text'], str):\n",
    "            urls_in_text = url_pattern.findall(post['text'])\n",
    "            if urls_in_text:\n",
    "#                 print(post['id'], post['text'])\n",
    "                counts[\"total_url_from_text\"] += len(urls_in_text)\n",
    "                counts[\"post_with_url\"] += 1\n",
    "        if 'fwd' in post:\n",
    "            counts[\"total_fwd_posts\"] += 1\n",
    "        \n",
    "        if 'text' in post and isinstance(post['text'], str):\n",
    "            text_length = len(post['text'])\n",
    "            if text_length < counts[\"lowest_text_length\"]:\n",
    "                counts[\"lowest_text_length\"] = text_length\n",
    "            if text_length > counts[\"highest_text_length\"]:\n",
    "                counts[\"highest_text_length\"] = text_length\n",
    "    \n",
    "    # average views\n",
    "    if counts[\"post_with_views\"] > 0:\n",
    "        counts[\"average_views\"] = counts[\"total_views\"] / counts[\"post_with_views\"]\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sys.stdout = open('QC.txt', 'w')\n",
    "\n",
    "main_folder = \"\"\n",
    "\n",
    "period_totals = {}\n",
    "\n",
    "\n",
    "# specify the order for the graph\n",
    "period_order = [\"011522-030122\", \"040122-050122\", \"060122-070122\", \"090122-101622\", \n",
    "                \"110122-120122\", \"020123-030123\", \"060123-070723\"]\n",
    "\n",
    "for folder_name in os.listdir(main_folder):\n",
    "#     if folder_name == \"eshkinkrot\":\n",
    "        folder_path = os.path.join(main_folder, folder_name)\n",
    "\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                if file_name.endswith(\".json\") and file_name != 'channel_info.json':\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                    num_posts = len(data)\n",
    "                    period = str(file_name.rsplit('_', 1)[-1].rsplit('.', 1)[0])\n",
    "                    print(f\"Folder: {folder_name}, Period: {period}, Num Posts: {num_posts}\")\n",
    "\n",
    "                    metrics = count_metrics(data)\n",
    "                    print(\"QA/QC metrics: \")\n",
    "                    for key, value in metrics.items():\n",
    "                        if key not in [\"url_new\", \"url_old\"]:\n",
    "                            print(f\"  {key}: {value}\")\n",
    "                    print()\n",
    "sys.stdout.close()\n",
    "sys.stdout = sys.__stdout__  # reset output to console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.stdout = open('QC.txt', 'w')\n",
    "\n",
    "main_folder = \"\"\n",
    "\n",
    "period_totals = {}\n",
    "\n",
    "\n",
    "# specify the order for the graph\n",
    "period_order = [\"011522-030122\", \"040122-050122\", \"060122-070122\", \"090122-101622\", \n",
    "                \"110122-120122\", \"020123-030123\", \"060123-070723\"]\n",
    "\n",
    "# Function to check if a given ID exists in the provided JSON data\n",
    "def id_exists_in_data(id, data):\n",
    "    for i in data.keys():\n",
    "        post = data[i]\n",
    "        if post.get('id') == id:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for folder_name in os.listdir(main_folder):\n",
    "        print(folder_name)\n",
    "        folder_path = os.path.join(main_folder, folder_name)\n",
    "        image_folder_path = os.path.join(folder_path, \"images\")\n",
    "        doc_folder_path = os.path.join(folder_path, \"documents\")\n",
    "        extracted_file_ids = []\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Images and Docs \n",
    "            if os.path.isdir(image_folder_path) and os.path.isdir(doc_folder_path) :\n",
    "                for file_name in os.listdir(image_folder_path)+os.listdir(doc_folder_path):\n",
    "                    if \"photo\" in file_name or \"doc\" in file_name:\n",
    "                        # Extract the number that goes after \"photo\" or \"doc\" from each filename\n",
    "                        try:\n",
    "                            id_str = file_name.split(\"photo\")[1].split(\".\")[0] if \"photo\" in file_name else file_name.split(\"doc\")[1].split(\".\")[0]\n",
    "                            extracted_file_ids.append(int(id_str))\n",
    "                        except (IndexError, ValueError):\n",
    "                            print(f\"Failed to extract ID from {file_name}\")\n",
    "            # Go over the messages json files\n",
    "            json_files = [file for file in os.listdir(folder_path) if file.endswith(\".json\") and file_name != 'channel_info.json']\n",
    "            missing_associations = []\n",
    "            for extracted_id in extracted_file_ids:\n",
    "                found = False\n",
    "                for file_name in json_files:\n",
    "                    with open(os.path.join(folder_path, file_name), 'r') as json_file:\n",
    "                        data = json.load(json_file)\n",
    "                    if id_exists_in_data(extracted_id, data):\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    missing_associations.append(extracted_id)\n",
    "        # Print or process the missing associations\n",
    "        print(f\"Folder: {folder_name}, Missing: {missing_associations}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
